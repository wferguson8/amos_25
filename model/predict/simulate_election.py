"""

Created on Mon May 10 25
@author: Will Ferguson
@email: will.ferguson@teenpact.com, iamwillferguson@gmail.com

This file uses the prior distribution constructed at training time, and the posterior distribution calculated
as a weighted average of modern polling data (TBD: construct this posterior) to simulate a large number of elections
and record the results (TBD: where the results are stored).

"""
import random
from typing import Dict, Tuple, Any

import numpy as np
import pandas as pd
import os
from sqlalchemy import create_engine
from sqlalchemy.engine import URL
import psycopg2
from pathlib import Path
from tqdm import tqdm
from dotenv import load_dotenv
import arviz as az
from concurrent.futures import ProcessPoolExecutor, as_completed

# Local Imports
from utils import electoral_college_info, state_data
from model.fit.data.utils import home_states

load_dotenv() # For DB Uploads

posterior_path = Path('./data/compiled_output.csv')
summary = Path('data/summary_test.csv')
winner_path = Path('data/winner_test.csv')

labels = ["C", "P", "V"]

def simulate_election(sample: pd.DataFrame) -> Tuple[Dict[str, int], Dict[Any, Any]]:
    """
    Given a sample from a posterior distribution, simulate the outcome of an election in 50 states.

    :param sample: A DataFrame containing the posterior distribution sampling of 50 states for a synthetic election
    :return: A dictionary containing the winners by state
    """

    from model.fit.create_prior import model
    posterior = az.from_netcdf("../fit/data/posterior.nc")

    predicted_totals = {
        "P": 0,
        "V": 0,
        "C": 0
    }
    predicted_by_state = {}

    model.predict(
        idata=posterior,  # The data generated by model.fit()
        data=sample,  # TODO: Get better data!!!
        kind='response'
    )

    data = posterior.posterior_predictive

    data: pd.DataFrame = data.to_dataframe().reset_index()  # convert to dataframe, should have the labels all added
    data['state'] = sample['state'].values[data['__obs__']]

    state_predictions: pd.Series = (
        data.groupby('state')['winner']
        .agg(lambda x: x.value_counts().idxmax())
    )
    # Update the results based on the winner of each state
    completed_states = []
    for state, winner in zip(state_predictions.index, state_predictions.values):
        w = labels[int(winner)]
        if w == "P":
            if random.random() < 0.10 and state not in home_states["2025"]["Perseverance"]:
                w = random.choice(["C", "V"]) # This is where things get a little bit demented
        value = electoral_college_info[state]
        predicted_totals[w] += value
        predicted_by_state[state] = w
        completed_states.append(state)

    remaining_states = list(set(electoral_college_info.keys()) - set(completed_states))
    for state in remaining_states:
        w = random.choice(labels)
        value = electoral_college_info[state]
        predicted_totals[w] += value
        predicted_by_state[state] = w

    return predicted_totals, predicted_by_state


def calculate_results(totals: Dict[str, int]) -> str:
    """

    Return the winner

    :param totals: The totals for each party candidate
    :return: Str containing the party that won the election
    """
    return list(totals.keys())[list(totals.values()).index(max(totals.values()))]

def upload_results(df: pd.DataFrame, table:str) -> None:
    """
    Upload the results to the database so that the hosted API can actually access the information.

    :return: None
    """

    import logging
    logging.basicConfig(level=logging.INFO)

    url = os.getenv('DB_CONNECTION')
    if not url:
        raise ValueError("DB_CONNECTION environment variable is not set.")

    print("Connecting to database...")
    engine = create_engine(url)
    print("Connection established.")

    try:
        print("Uploading to table:", table)
        df.to_sql(table, engine, if_exists='replace', index=False)
        print("Upload successful.")
    except Exception as e:
        print("Upload failed:", e)


def main():

    # Load the posterior distribution

    os.chdir(Path(__file__).parent.absolute())
    data = pd.read_csv(posterior_path)

    predictors = [
        "vs_p", "hs_p", "vs_v", "hs_v", "vs_c", "hs_c", "vs_o",
        "pop_p", "pop_v", "pop_c", "pop_o"
    ]

    def weighted_avg(group):
        weights = group["size"]
        return pd.Series({
            col: np.average(group[col], weights=weights)
            for col in predictors
        })

    # Group by state and apply
    data = data.groupby("state").apply(weighted_avg).reset_index()

    # Create dataframe you're going to use to upload the summary of results
    summary_cols = [
        'state',
        'sims_p',  # Expressed as percents at the end
        'sims_v',
        'sims_c',
        'sims_w' # Number of sims where the winner won the election
    ]

    winner_db = {
        'wins_p': 0,
        'wins_v': 0,
        'wins_c': 0
    }

    summary_df = pd.DataFrame(data=state_data, columns=summary_cols)  # empty dataframe
    summary_df.set_index("state", inplace=True)

    # Simulate a whole bunch of elections (increase once testing is done completely)
    NUM_SIMS = 10000
    with ProcessPoolExecutor() as executor:
        futures = [executor.submit(simulate_election, data) for _ in range(NUM_SIMS)]
        for future in tqdm(as_completed(futures)):
            totals, by_state = future.result()
            winner = calculate_results(totals)
            winner_db[f"wins_{winner.lower()}"] += 1

            for k, v in by_state.items():
                summary_df.loc[k, f"sims_{v.lower()}"] += 1
                if v == winner:
                    summary_df.loc[k, 'sims_w'] += 1

    # convert totals to percentages
    summary_df = summary_df / NUM_SIMS

    # Upload results
    # upload_results(summary_df, 'summary')

    summary_df.to_csv(summary)
    winner_df = pd.DataFrame(data=[winner_db])

    # upload_results(winner_df, 'winner')
    winner_df.to_csv(winner_path)


if __name__ == '__main__':
    main()